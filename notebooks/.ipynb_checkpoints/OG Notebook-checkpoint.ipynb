{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ioEdIS68leH"
   },
   "source": [
    "# What am i doing here?\n",
    "\n",
    "I would love for pretrained neural networks to learn continuously while they are facing real world data to ensure their robustness and make them more intelligent.\n",
    "\n",
    "Before I started studying AI i actually thought this was the case. I mean sure. ANNs train with labelled data to then label unknown data. So, further training would require us to handlabel a lot of these real life data points. Wasn't this the reason why we trained the ANN in the first place? So we don't have to do that? This is the most exhausting part of facing a new task with ML. Also this kind of screams overfitting haha\n",
    "\n",
    "How about, we let an ensemble of networks make the prediction and if 1 out of the 3 or 5 networks is out of line we train it using the label the other networks picked. No hand labelling. No overfitting. \n",
    "\n",
    ":-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJbEby9CUbUu"
   },
   "source": [
    "#Greetings!\n",
    "This is where I will lay down the framework for my bachelor's thesis. I hope this works out. It is especially difficult for me to find a start. To pick up the work. But. I will now. How about a step-by-step plan?\n",
    "\n",
    "- How do I need to prepare the data?\n",
    "\n",
    "- What are 5 architectures that are simple and work well on MNIST?\n",
    "\n",
    "- What does the post-training look like?\n",
    "\n",
    "- How do I abstract the data to simulate real world data process change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4OjFzui4m2l"
   },
   "source": [
    "How about some more general questions that I could focus on in my writing. To further discuss and compare my work to what others accomplished before me. To make sense of my work and put it into context. Set some measurements and results i want to achieve with my approach.\n",
    "\n",
    "- What other \"keep my model robust and accurate during application\" methods are out their?\n",
    "\n",
    "- What are their advantages and disadvantages?\n",
    "\n",
    "- What do they aim for?\n",
    "\n",
    "- Where does my concept finds its place in the realm of ensemble networks?\n",
    "\n",
    "- Where are weaknesses in my implementation of the idea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2366,
     "status": "ok",
     "timestamp": 1637050281946,
     "user": {
      "displayName": "Heizas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBSz45p53xJwpJ_CdBLR5D9RiKfje__0D0IrFK=s64",
      "userId": "07740536896006343917"
     },
     "user_tz": -60
    },
    "id": "_smUlNbYUVoT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZOoSoL9xFlH"
   },
   "source": [
    "## 1. DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1029,
     "status": "ok",
     "timestamp": 1637050297937,
     "user": {
      "displayName": "Heizas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBSz45p53xJwpJ_CdBLR5D9RiKfje__0D0IrFK=s64",
      "userId": "07740536896006343917"
     },
     "user_tz": -60
    },
    "id": "NrgUBRQbqBUj",
    "outputId": "473ed5d7-6c42-4cf3-ddc8-6f58b286cfa7"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x):\n",
    "    x = x.numpy()\n",
    "    if x.ndim == 2:\n",
    "        x = x[0]\n",
    "    fig, ax = plt.subplots(1)\n",
    "    x = x.reshape((28,28))\n",
    "    ax.imshow(x, cmap='gray')\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "def getmax(x):\n",
    "    x = list(x.numpy())\n",
    "    prob = np.max(x)\n",
    "    pred = x.index(prob)\n",
    "    return prob, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1637050301091,
     "user": {
      "displayName": "Heizas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBSz45p53xJwpJ_CdBLR5D9RiKfje__0D0IrFK=s64",
      "userId": "07740536896006343917"
     },
     "user_tz": -60
    },
    "id": "nPiJOhGBqack",
    "outputId": "5db1f8cd-303a-4751-e5f4-372fe85d4267"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check it out\n",
    "fig, ax = plt.subplots(1,5)\n",
    "for i in range(5):\n",
    "\n",
    "    # Readout an image and the corresponding label.\n",
    "    img = train_images[i]\n",
    "    lbl = train_labels[i]\n",
    "\n",
    "    ax[i].imshow(img, cmap='gray')\n",
    "    ax[i].set_title(lbl)\n",
    "    ax[i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1925,
     "status": "ok",
     "timestamp": 1637050309203,
     "user": {
      "displayName": "Heizas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBSz45p53xJwpJ_CdBLR5D9RiKfje__0D0IrFK=s64",
      "userId": "07740536896006343917"
     },
     "user_tz": -60
    },
    "id": "3QVF1ACzvVMe"
   },
   "outputs": [],
   "source": [
    "# tf.data.Dataset.from_tensor_slices creates a tf.dataset from a tensor. The elements of the dataset are slices of the first tensor dimension\n",
    "train_dataset_images = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "# the mapping function maps each  element to the dataset to the value defined by the lambda function\n",
    "# reshapes each tensor to vector\n",
    "train_dataset_images = train_dataset_images.map(lambda img : tf.reshape(img, (-1,)))\n",
    "\n",
    "\n",
    "train_dataset_targets = tf.data.Dataset.from_tensor_slices(train_labels)\n",
    "# we want the labels to be onehot encoded\n",
    "train_dataset_targets = train_dataset_targets.map(lambda t : tf.one_hot(t, 10))\n",
    "\n",
    "# zip together input and labels\n",
    "train_dataset = tf.data.Dataset.zip((train_dataset_images, train_dataset_targets))\n",
    "train_dataset = train_dataset.batch(128)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=128)\n",
    "\n",
    "# repeat for the test dataset\n",
    "test_dataset_images = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "test_dataset_images = test_dataset_images.map(lambda img : tf.reshape(img, (-1,)))\n",
    "\n",
    "test_dataset_targets = tf.data.Dataset.from_tensor_slices(test_labels)\n",
    "test_dataset_targets = test_dataset_targets.map(lambda t : tf.one_hot(t, 10))\n",
    "\n",
    "test_dataset = tf.data.Dataset.zip((test_dataset_images, test_dataset_targets))\n",
    "test_dataset = test_dataset.batch(128)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2407,
     "status": "ok",
     "timestamp": 1637051142383,
     "user": {
      "displayName": "Heizas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBSz45p53xJwpJ_CdBLR5D9RiKfje__0D0IrFK=s64",
      "userId": "07740536896006343917"
     },
     "user_tz": -60
    },
    "id": "oc9qoLwt0REk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SkipDataset shapes: ((None, 784), (None, 10)), types: (tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting it for posttraining\n",
    "split_num = int(40000/128)\n",
    "train_dataset_pre = train_dataset.take(split_num)\n",
    "train_dataset_post = train_dataset.skip(split_num)\n",
    "train_dataset_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num1 = 0\n",
    "num2 = 1\n",
    "\n",
    "# Create binary ds\n",
    "mask = np.logical_or(train_labels == num1, train_labels == num2)\n",
    "train_images_bi = train_images[mask]\n",
    "train_labels_bi = train_labels[mask]\n",
    "\n",
    "# tf.data.Dataset.from_tensor_slices creates a tf.dataset from a tensor. The elements of the dataset are slices of the first tensor dimension\n",
    "train_dataset_images = tf.data.Dataset.from_tensor_slices(train_images_bi)\n",
    "# the mapping function maps each  element to the dataset to the value defined by the lambda function\n",
    "# reshapes each tensor to vector\n",
    "train_dataset_images = train_dataset_images.map(lambda img : tf.reshape(img, (-1,)))\n",
    "\n",
    "\n",
    "train_dataset_targets = tf.data.Dataset.from_tensor_slices(train_labels_bi)\n",
    "# we want the labels to be onehot encoded\n",
    "train_dataset_targets = train_dataset_targets.map(lambda t : tf.one_hot(t, 1))\n",
    "\n",
    "# zip together input and labels\n",
    "train_ds_bi = tf.data.Dataset.zip((train_dataset_images, train_dataset_targets))\n",
    "train_ds_bi = train_ds_bi.batch(128)\n",
    "train_ds_bi = train_ds_bi.shuffle(buffer_size=128)\n",
    "\n",
    "# create 2nd mask\n",
    "mask = np.logical_or(test_labels == num1, test_labels == num2)\n",
    "test_images_bi = test_images[mask]\n",
    "test_labels_bi = test_labels[mask]\n",
    "\n",
    "# repeat for the test dataset\n",
    "test_dataset_images = tf.data.Dataset.from_tensor_slices(test_images_bi)\n",
    "test_dataset_images = test_dataset_images.map(lambda img : tf.reshape(img, (-1,)))\n",
    "\n",
    "test_dataset_targets = tf.data.Dataset.from_tensor_slices(test_labels_bi)\n",
    "test_dataset_targets = test_dataset_targets.map(lambda t : tf.one_hot(t, 1))\n",
    "\n",
    "test_ds_bi = tf.data.Dataset.zip((test_dataset_images, test_dataset_targets))\n",
    "test_ds_bi = test_ds_bi.batch(128)\n",
    "test_ds_bi = test_ds_bi.shuffle(buffer_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAENklEQVR4nO3dMUoeWxiA4TvXgFgIrkCwcAGCZSqLNJYuxkXYi5uwcg+CYidYhHQ2qS0Dce4GdLw4v/+8Js9T+jGH07x84CFxGMfxH6Dn36UvALxMnBAlTogSJ0SJE6K+TA2HYfCrXPhg4zgOL/3c5oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRH1Z+gKs1tXV1eT8+Ph4cn52dvbq7PT09F134n1sTogSJ0SJE6LECVHihChxQpQ4Ico75x/mrXfMcRwn5/v7+6u8DjPYnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKP9k7JM5PDxc+gqsic0JUeKEKHFClDghSpwQJU6IEidEeef8ZE5OTpa+Amtic0KUOCFKnBAlTogSJ0SJE6LECVHeOT+Zr1+/Ts6HYZh1/vX19azvWR2bE6LECVHihChxQpQ4IUqcECVOiPLO+YcZx3HW/Pv376u8DjPYnBAlTogSJ0SJE6LECVHihChPKX+ZX79+Tc5//vy5ppvwFpsTosQJUeKEKHFClDghSpwQJU6I8s4Zs7m5OTnf2tqadf7j4+Pk/Pb2dtb5rI7NCVHihChxQpQ4IUqcECVOiBInRHnnjNnb25ucHxwczDr/8vJy1vesj80JUeKEKHFClDghSpwQJU6IEidEeeeMOT09nZwPw/ChczpsTogSJ0SJE6LECVHihChxQpQ4Ico7Z8zx8fHkfBzHWeff39/P+p71sTkhSpwQJU6IEidEiROixAlRnlL+Mnd3d0tfgf/J5oQocUKUOCFKnBAlTogSJ0SJE6K8cy5ge3v71dnGxsass29ubibnP378mHU+62NzQpQ4IUqcECVOiBInRIkTosQJUd45F3B0dPTqbGdnZ9bZDw8Pk/Pfv3/POp/1sTkhSpwQJU6IEidEiROixAlR4oQo75wxwzDM+v76+npFN2FpNidEiROixAlR4oQocUKUOCHKU0rMOI6zvn9+fl7RTViazQlR4oQocUKUOCFKnBAlTogSJ0R551zA7u7u0lfgE7A5IUqcECVOiBInRIkTosQJUeKEKO+cC5j6E4BzPT09fdjZrJfNCVHihChxQpQ4IUqcECVOiBInRHnnXMDFxcWrs2/fvk1+e35+Pjm/vLx8153osTkhSpwQJU6IEidEiROixAlR4oSoYervQQ7DMO+PRQJvGsdxeOnnNidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghavK/xgSWY3NClDghSpwQJU6IEidEiROi/gNXaWCUAz4esAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x,y in test_ds_bi:\n",
    "    plot(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((None, 784), (None, 1)), types: (tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting it for posttraining\n",
    "split_num = int(40000/128)\n",
    "train_ds_bi_pre = train_ds_bi.take(split_num)\n",
    "train_ds_bi_post = train_ds_bi.skip(split_num)\n",
    "train_ds_bi_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlhzapMfxH5C"
   },
   "source": [
    "# 2. MODELS\n",
    "Well, we gotta figure out which architectures work well for our dataset. At best, we find them already trained for exactly our dataset on the internet and download them. Noice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1637050310632,
     "user": {
      "displayName": "Heizas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBSz45p53xJwpJ_CdBLR5D9RiKfje__0D0IrFK=s64",
      "userId": "07740536896006343917"
     },
     "user_tz": -60
    },
    "id": "sMz14f70Xr-2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1637050312427,
     "user": {
      "displayName": "Heizas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBSz45p53xJwpJ_CdBLR5D9RiKfje__0D0IrFK=s64",
      "userId": "07740536896006343917"
     },
     "user_tz": -60
    },
    "id": "hfzywTc6xK44"
   },
   "outputs": [],
   "source": [
    "class NN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, nodes=[256, 256], num_classes=10):\n",
    "        super(NN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.model = [tf.keras.layers.Dense(x, activation=tf.keras.activations.sigmoid) for x in nodes]\n",
    "        self.model.append(tf.keras.layers.Dense(num_classes, activation=tf.keras.activations.softmax))\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        for layer in self.model:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, config=[(32, 3)], num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.model = [(tf.keras.layers.Conv2D(filters=x,\n",
    "                                              kernel_size=y,\n",
    "                                              padding='same',\n",
    "                                              activation=tf.keras.activations.relu),\n",
    "                       tf.keras.layers.MaxPool2D(pool_size=(2,2))) for (x,y) in config]\n",
    "        # Flatten the model tuple list\n",
    "        self.model = list(sum(self.model, ()))\n",
    "        self.out = [tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                       tf.keras.layers.Dense(128, activation=tf.keras.activations.relu),\n",
    "                       tf.keras.layers.Dense(self.num_classes, activation=tf.keras.activations.softmax)]\n",
    "\n",
    "    def call(self, x):\n",
    "        if len(x.shape) == 1:\n",
    "            x = tf.reshape(x, (1, 28, 28, 1))\n",
    "        else:\n",
    "            x = tf.reshape(x, (x.shape[0], 28, 28, 1))\n",
    "        for layer in self.model:\n",
    "            x = layer(x)\n",
    "        for layer in self.out:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1637050524121,
     "user": {
      "displayName": "Heizas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBSz45p53xJwpJ_CdBLR5D9RiKfje__0D0IrFK=s64",
      "userId": "07740536896006343917"
     },
     "user_tz": -60
    },
    "id": "ASTVV6eXdkyk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_classes = 2\\n# Deep model\\nmodel1 = NN([256], num_classes)\\n# Broad Model\\nmodel2 = NN([128], num_classes)\\n# Small Model\\nmodel3 = NN([64, 64], num_classes)\\n# pyramid\\nmodel4 = NN([32, 32, 32], num_classes)\\n# BIGGEST\\nmodel5 = NN([16, 16, 16, 16], num_classes)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"num_classes = 2\n",
    "# Deep model\n",
    "model1 = NN([256], num_classes)\n",
    "# Broad Model\n",
    "model2 = NN([128], num_classes)\n",
    "# Small Model\n",
    "model3 = NN([64, 64], num_classes)\n",
    "# pyramid\n",
    "model4 = NN([32, 32, 32], num_classes)\n",
    "# BIGGEST\n",
    "model5 = NN([16, 16, 16, 16], num_classes)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDv9abYxzSQg"
   },
   "source": [
    "# 3. PRE TRAINING\n",
    "This is where we train our models to a certain accuracy or download pretrained models. For training we need to input our datapoints to every network simultaneously and declare the prediciton by vote.\n",
    "\n",
    "For the post-training the following intel must be collected if one network makes a different prediction than the others: \n",
    "- The datapoint\n",
    "- The label given by the najority of the networks\n",
    "- The index of the presumably wrong model\n",
    "\n",
    "So a triplet. With each post-training iteration we got a dataset for every model and they train individually on these errors and not on the presumably correct predictions to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1637050333774,
     "user": {
      "displayName": "Heizas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBSz45p53xJwpJ_CdBLR5D9RiKfje__0D0IrFK=s64",
      "userId": "07740536896006343917"
     },
     "user_tz": -60
    },
    "id": "Rcq1vL9ezUYg"
   },
   "outputs": [],
   "source": [
    "def train_step(model, input, target, loss_function, optimizer):\n",
    "  # loss_object and optimizer_object are instances of respective tensorflow classes\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = model(input)\n",
    "        print(prediction)\n",
    "        print(target)\n",
    "        loss = loss_function(target, prediction)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss \n",
    "\n",
    "def test(model, test_data, loss_function):\n",
    "    # test over complete test data\n",
    "\n",
    "    test_accuracy_aggregator = []\n",
    "    test_loss_aggregator = []\n",
    "\n",
    "    for (input, target) in test_data:\n",
    "        prediction = model(input)\n",
    "        sample_test_loss = loss_function(target, prediction)\n",
    "        sample_test_accuracy =  np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
    "        sample_test_accuracy = np.mean(sample_test_accuracy)\n",
    "        test_loss_aggregator.append(sample_test_loss.numpy())\n",
    "        test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
    "\n",
    "    test_loss = np.mean(test_loss_aggregator)\n",
    "    test_accuracy = np.mean(test_accuracy_aggregator)\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1637051387861,
     "user": {
      "displayName": "Heizas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBSz45p53xJwpJ_CdBLR5D9RiKfje__0D0IrFK=s64",
      "userId": "07740536896006343917"
     },
     "user_tz": -60
    },
    "id": "ET-IoQzdzXxr"
   },
   "outputs": [],
   "source": [
    "def pretraining(model, num_epochs=10, bi=False):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    ### Hyperparameters\n",
    "    learning_rate = 0.001\n",
    "    running_average_factor = 0.95\n",
    "\n",
    "    # Initialize the loss: categorical cross entropy. Check out 'tf.keras.losses'.\n",
    "    cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    # Initialize the optimizer: Adam with default parameters. Check out 'tf.keras.optimizers'\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "    # Initialize lists for later visualization.\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # Get datasets\n",
    "    if bi==False:\n",
    "        global train_dataset_pre\n",
    "        global test_dataset\n",
    "    else:\n",
    "        global train_ds_bi\n",
    "        global test_ds_bi\n",
    "        train_dataset_pre = train_ds_bi_pre\n",
    "        test_dataset = test_ds_bi\n",
    "\n",
    "    #testing once before we begin\n",
    "    test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    #check how model performs on train data once before we begin\n",
    "    train_loss, _ = test(model, train_dataset_pre, cross_entropy_loss)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # We train for num_epochs epochs.\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch: __ ' + str(epoch))\n",
    "\n",
    "        train_dataset_pre = train_dataset_pre.shuffle(buffer_size=128)\n",
    "        test_dataset = test_dataset.shuffle(buffer_size=128)\n",
    "\n",
    "        #training (and checking in with training)\n",
    "        running_average = 0\n",
    "        for (input,target) in train_dataset_pre:\n",
    "            train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
    "            running_average = running_average_factor * running_average  + (1 - running_average_factor) * train_loss\n",
    "        train_losses.append(running_average)\n",
    "\n",
    "        #testing\n",
    "        test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        print(f\"LOSS {test_loss} ::: ACC {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "# Deep model\n",
    "model1 = NN([128, 128], num_classes)\n",
    "# Broad Model\n",
    "model2 = NN([512], num_classes)\n",
    "# Small Model\n",
    "model3 = NN([256, 256], num_classes)\n",
    "# cnn\n",
    "model4 = CNN([(32, 3), (64, 5), (128, 7)], num_classes)\n",
    "# cnn small\n",
    "model5 = CNN([(32, 3), (64, 5)], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: __ 0\n",
      "LOSS 0.3688032327196266 ::: ACC 0.9025909810126582\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "pretraining(model1, 1, bi=False)\n",
    "pretraining(model2, 1, bi=False)\n",
    "pretraining(model3, 1, bi=False)\n",
    "pretraining(model4, 1, bi=False)\n",
    "pretraining(model5, 1, bi=False)\n",
    "model1.save_weights('code/models/NN128128')\n",
    "model2.save_weights('code/models/NN512')\n",
    "model3.save_weights('code/models/NN256256')\n",
    "model4.save_weights('code/models/CNN3264128')\n",
    "model5.save_weights('code/models/CNN3264')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd6b1cf5c50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_weights('code/models/NN128128')\n",
    "model2.load_weights('code/models/NN512')\n",
    "model3.load_weights('code/models/NN256256')\n",
    "model4.load_weights('code/models/CNN3264128')\n",
    "model5.load_weights('code/models/CNN3264')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fplm9evFzdVO"
   },
   "source": [
    "# 4. POST TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktX9SdHiK3F6"
   },
   "source": [
    "Post training should work as followed:\n",
    "\n",
    "While applying the ensemble network in a real world environment, we collect the new datapoints where the prediction was not unanimous and label them with our prediction and the index of the one network that predicted something else.\n",
    "\n",
    "We split the dataset by the last variable, after we collected enough datapoints and then train each network on their own to ensure robustness for the ensemble network while facing changing real life data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qO59vCaL5RS7"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "BKn_zkOLzfwz"
   },
   "outputs": [],
   "source": [
    "class Ensemble(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, models):\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.__data = None\n",
    "        self.__missed_data = None\n",
    "        self.num_classes = models[0].num_classes\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"The ensemble is either predicting unanimous, \n",
    "        or one model is off and the datapoint is collected\n",
    "         for this models posttraining.\n",
    "         In any other case the ensemble returns [0.]*10 == No prediction.\n",
    "         Needs to be handlabeled.\n",
    "         \"\"\"\n",
    "        \n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            result = list(model(x).numpy())\n",
    "            predictions.append(np.argmax(result, axis=1))\n",
    "        \n",
    "        # Transpose to let every index be the predictions for 1 datapoint\n",
    "        x = x.numpy()\n",
    "        predictions = np.transpose(predictions)\n",
    "        output = np.zeros((len(x), self.num_classes))\n",
    "        for idx, prediction in enumerate(predictions):\n",
    "            \n",
    "            # All nets give same predictions\n",
    "            if len(set(prediction)) == 1:\n",
    "                output[idx] = tf.one_hot(prediction[0], self.num_classes)\n",
    "                continue\n",
    "\n",
    "            # Nets give 2 different answers\n",
    "            if len(set(prediction)) == 2:\n",
    "                c = Counter(prediction)\n",
    "                pred1 = list(set(prediction))[0]\n",
    "                pred2 = list(set(prediction))[1]\n",
    "                pred1count = c[pred1]\n",
    "                pred2count = c[pred2]\n",
    "\n",
    "                if pred1count == 1:\n",
    "                    self.__collect_data(x, label=pred2, wrong_model=list(prediction).index(pred1))\n",
    "                    output[idx] = tf.one_hot(list(set(prediction))[1], self.num_classes)\n",
    "                    continue\n",
    "\n",
    "                elif pred2count == 1:\n",
    "                    self.__collect_data(x, label=pred1, wrong_model=list(prediction).index(pred2))\n",
    "                    output[idx] = tf.one_hot(list(set(prediction))[0], self.num_classes)\n",
    "                    continue\n",
    "    \n",
    "            # Unsure. Save for later review.\n",
    "            self.__collect_miss(x[idx])\n",
    "            output[idx] = [0.] * self.num_classes # := Unsure\n",
    "            \n",
    "        return tf.convert_to_tensor(output)\n",
    "\n",
    "    def __collect_data(self, x, label, wrong_model):\n",
    "        \"\"\"Add the current datapoint to self.data \n",
    "        with the index of the model that needs to be trained on that datapoint\n",
    "        and the label predicted by the other networks.\n",
    "        \"\"\"\n",
    "        img = tf.data.Dataset.from_tensor_slices(x)\n",
    "        label_onehot = tf.data.Dataset.from_tensor_slices([label]).map(lambda x: tf.one_hot(x, self.num_classes))\n",
    "        wrong_model = tf.data.Dataset.from_tensor_slices([wrong_model])\n",
    "        datapoint = tf.data.Dataset.zip((img, label_onehot, wrong_model))\n",
    "        if self.__data == None:\n",
    "            self.__data = datapoint\n",
    "        else:\n",
    "            self.__data = self.__data.concatenate(datapoint)\n",
    "\n",
    "    def __collect_miss(self, x):\n",
    "        \"\"\"Collect a datapoint which could not be determined.\n",
    "        Review by hand later.\n",
    "        \"\"\"\n",
    "        ds = tf.data.Dataset.from_tensor_slices([x])\n",
    "        if self.__missed_data == None:\n",
    "            self.__missed_data = ds\n",
    "        else:\n",
    "            self.__missed_data = self.__missed_data.concatenate(ds)\n",
    "            \n",
    "    def get_data(self):\n",
    "        return self.__data#.map(lambda x,y,z: (tf.squeeze(x),tf.squeeze(y),z))\n",
    "\n",
    "    def get_missed_data(self):\n",
    "        return self.__missed_data#.map(lambda x: tf.squeeze(x))\n",
    "                                            \n",
    "    def reset_data(self):\n",
    "        \"\"\"Data should be reset after each posttraining.\"\"\"\n",
    "        self.__data = None\n",
    "        self.__missed_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "NtFCdz48bn_T"
   },
   "outputs": [],
   "source": [
    "ensemble = Ensemble([model1, model2, model3, model4, model5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhMLII6KygS4"
   },
   "source": [
    "#### Some helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jvn1T4ojyljC"
   },
   "source": [
    "#### Check how the nets individually predict and getting the datacollecting right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1626099834987,
     "user": {
      "displayName": "Heizas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBSz45p53xJwpJ_CdBLR5D9RiKfje__0D0IrFK=s64",
      "userId": "07740536896006343917"
     },
     "user_tz": -120
    },
    "id": "4qr0cDU7mn14",
    "outputId": "5e5a6ce8-ea4e-4def-8401-b1d41c7ded60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label:  (1.0, 9)\n",
      "Model 1: (0.8029706659401826, 9)\n",
      "Model 1: (0.9603093853196627, 9)\n",
      "Model 1: (0.9356488615043704, 9)\n",
      "Model 1: (0.9792022384897237, 9)\n",
      "Model 1: (0.362127376709741, 9)\n",
      "Ensemble: (1.0, 9)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x,y in test_dataset.unbatch():\n",
    "    plot(x)\n",
    "    print(\"Actual Label: \", getmax(y))\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    for model in ensemble.models:\n",
    "        print(f\"Model 1: {getmax(model(x)[0])}\")\n",
    "    print(f\"Ensemble: {getmax(ensemble(x)[0])}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_mXMGAdyz6U"
   },
   "source": [
    "### Getting started with posttraining framework\n",
    "\n",
    "For the posttraining we have to split our dataset by the last variable in the datapoint and then train each model in the ensemble network individually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting data \n",
    "ensemble.reset_data()\n",
    "for (input, label) in train_dataset_post.take(1):\n",
    "    pred = ensemble(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ensemble.get_missed_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ensemble.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.44705882 0.76862745\n",
      " 0.99607843 0.79607843 0.0745098  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.18039216 0.98431373 0.99215686 0.99215686 0.99215686\n",
      " 0.76862745 0.05098039 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.20392157 0.91372549\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.47058824\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.02745098 0.7372549  0.99215686 0.99215686 0.76862745\n",
      " 0.43529412 0.15686275 0.83921569 0.94117647 0.1372549  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.08235294 0.78823529\n",
      " 0.99215686 0.99215686 0.58823529 0.0627451  0.         0.\n",
      " 0.6627451  0.99215686 0.29019608 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.32156863 0.99215686 0.99215686 0.60392157\n",
      " 0.04705882 0.         0.         0.05490196 0.96470588 0.99215686\n",
      " 0.29019608 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.50588235 0.99215686 0.99215686 0.23529412 0.         0.\n",
      " 0.         0.05882353 0.99215686 0.92156863 0.08235294 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.04705882 0.7372549  0.99215686\n",
      " 0.96862745 0.19607843 0.         0.         0.         0.05882353\n",
      " 0.99215686 0.74117647 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.29803922 0.99215686 0.99215686 0.39215686 0.\n",
      " 0.         0.         0.         0.36078431 0.99215686 0.89411765\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.29411765\n",
      " 0.99215686 0.99215686 0.05490196 0.         0.         0.\n",
      " 0.04705882 0.86666667 0.99215686 0.58823529 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.29411765 0.99215686 0.99215686\n",
      " 0.05490196 0.         0.         0.         0.23529412 0.99215686\n",
      " 0.99215686 0.11764706 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.29803922 0.99215686 0.99215686 0.05490196 0.\n",
      " 0.         0.         0.48235294 0.99215686 0.92941176 0.09019608\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.29411765\n",
      " 0.99215686 0.84313725 0.03137255 0.         0.         0.19607843\n",
      " 0.9372549  0.99215686 0.54117647 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.29411765 0.99215686 0.65882353\n",
      " 0.         0.         0.         0.41176471 0.99215686 0.95294118\n",
      " 0.10980392 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.29803922 0.99215686 0.47058824 0.         0.\n",
      " 0.01960784 0.77647059 0.99607843 0.93333333 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.29411765\n",
      " 0.99215686 0.54509804 0.         0.         0.4745098  0.99215686\n",
      " 0.99215686 0.93333333 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.02352941 0.69803922 0.96862745\n",
      " 0.18431373 0.43921569 0.95686275 0.99215686 0.99607843 0.51764706\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.21960784 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.81960784 0.03921569 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00784314 0.45490196 0.98431373 0.99607843 0.99215686 0.92156863\n",
      " 0.31764706 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.56862745 0.75686275 0.6        0.2        0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ], shape=(784,), dtype=float64) tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32) tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x,y,z in ensemble.get_data().take(1):\n",
    "    print(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcatenateDataset shapes: (784,), types: tf.float64>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.get_missed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: ((None, 784), (None, 10)), types: (tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(128, 784), dtype=float64) tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(128, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for (x,y) in test_dataset.take(1):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# model counter\\ndist = np.zeros(5)\\nfor (x,y,z) in ensemble.data:\\n    dist[z] += 1\\n\\n# Show distribution of ensemble.data\\nfig, ax = plt.subplots()\\nax.bar(['Model 1', 'Model 2', 'Model 3', 'Model 4', 'Model 5'], dist)\\nplt.show()\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# model counter\n",
    "dist = np.zeros(5)\n",
    "for (x,y,z) in ensemble.data:\n",
    "    dist[z] += 1\n",
    "\n",
    "# Show distribution of ensemble.data\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(['Model 1', 'Model 2', 'Model 3', 'Model 4', 'Model 5'], dist)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8275316455696202"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, accuracy = test(ensemble, test_dataset, tf.keras.losses.CategoricalCrossentropy())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "E0ymgafGyzIE"
   },
   "outputs": [],
   "source": [
    "def posttraining(ensemble, num_epochs=10):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    ### Hyperparameters\n",
    "    learning_rate = 0.0005\n",
    "    running_average_factor = 0.95\n",
    "\n",
    "    # Initialize the loss: categorical cross entropy.\n",
    "    cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    # Initialize the optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "    # Initialize lists for later visualization.\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # Get datasets\n",
    "    train_ds_new = ensemble.get_data().batch(1)\n",
    "    #train_ds_new = train_ds_new.batch(128)\n",
    "    global test_dataset\n",
    "\n",
    "    # testing once before we begin\n",
    "    test_loss, test_accuracy = test(ensemble, test_dataset, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # We train for num_epochs epochs.\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch: __ ' + str(epoch))\n",
    "\n",
    "        #train_ds_new = train_ds_new.shuffle(buffer_size=128)\n",
    "        #test_dataset = test_dataset.shuffle(buffer_size=128)\n",
    "\n",
    "        # training (and checking in with training)\n",
    "        running_average = 0\n",
    "        for (input,target,model_index) in train_ds_new:\n",
    "            train_loss = train_step(ensemble.models[int(model_index)], input, target, cross_entropy_loss, optimizer)\n",
    "            print(train_loss)\n",
    "            running_average = running_average_factor * running_average  + (1 - running_average_factor) * train_loss\n",
    "        train_losses.append(running_average)\n",
    "\n",
    "        # testing\n",
    "        test_loss, test_accuracy = test(ensemble, test_dataset, cross_entropy_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        print(f\"LOSS {test_loss} ::: ACC {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posttraining(ensemble, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Epoch: __ 0\n",
    "tf.Tensor(\n",
    "[[0.00264005 0.00050683 0.03025515 0.00633547 0.10507429 0.00153617\n",
    "  0.00188732 0.37871936 0.00310558 0.46993977]], shape=(1, 10), dtype=float64)\n",
    "tf.Tensor([[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]], shape=(1, 10), dtype=float32)\n",
    "tf.Tensor(0.7551507353782654, shape=(), dtype=float64)\n",
    "tf.Tensor(\n",
    "[[8.68028860e-03 2.17086081e-08 6.06123716e-01 3.29074103e-02\n",
    "  7.51862222e-03 2.17260663e-01 3.01549415e-03 2.41740493e-02\n",
    "  7.87857775e-03 9.24411567e-02]], shape=(1, 10), dtype=float64)\n",
    "tf.Tensor([[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]], shape=(1, 10), dtype=float32)\n",
    "tf.Tensor(1.5266574621200562, shape=(), dtype=float64)\n",
    "...\n",
    "tf.Tensor(\n",
    "[[3.29172335e-03 1.95627526e-04 1.51238852e-01 1.10512080e-01\n",
    "  1.27141905e-03 2.37514641e-02 4.15754478e-03 3.68533133e-02\n",
    "  2.53630502e-01 4.15097474e-01]], shape=(1, 10), dtype=float64)\n",
    "tf.Tensor([[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]], shape=(1, 10), dtype=float32)\n",
    "tf.Tensor(3.300809860229492, shape=(), dtype=float64)\n",
    "LOSS nan ::: ACC 0.09760680379746836\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting theoretical approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(15,24))\n",
    "x = np.linspace(0,1)\n",
    "postrain3 = 3 * x**2 * (1-x)\n",
    "negtrain3 = 3 * (1-x)**2 * x\n",
    "postrain5 = 5 * x**4 * (1-x)\n",
    "negtrain3 = 3 * (1-x)**2 * x\n",
    "negtrain5 = 5 * (1-x)**4 * x\n",
    "miss5 = 10* ((1-x)**3*x**2 + x**3*(1-x)**2)\n",
    "allhit5 = x**5\n",
    "allmiss5 = (1-x)**5\n",
    "plt.suptitle(\"Theoretical Analysis of the method\")\n",
    "ax[0].set_title(\"Probability distribution of positive ensemble training\")\n",
    "ax[1].set_xlabel(\"Accuracy of the networks\")\n",
    "ax[0].set_xlabel(\"Accuracy of the networks\")\n",
    "ax[1].set_ylabel(\"Probabilty\")\n",
    "ax[0].set_ylabel(\"Probabilty of positive training\")\n",
    "ax[2].set_xlabel(\"Accuracy\")\n",
    "ax[2].set_ylabel(\"Probabilty\")\n",
    "ax[0].plot(x, postrain3)\n",
    "ax[0].plot(x, postrain5)\n",
    "ax[0].plot(x, negtrain3)\n",
    "ax[0].plot(x, negtrain5)\n",
    "ax[1].set_title(\"Probability distributions of all possible outcomes\")\n",
    "ax[1].plot(x, miss5)\n",
    "ax[1].plot(x, allhit5)\n",
    "ax[1].plot(x, allmiss5)\n",
    "ax[1].plot(x, postrain5)\n",
    "ax[1].plot(x, negtrain5)\n",
    "ax[1].plot(x, miss5+allhit5+allmiss5+negtrain5+postrain5)\n",
    "ax[2].plot(x, allhit5+postrain5)\n",
    "ax[2].plot(x, allmiss5+negtrain5)\n",
    "ax[2].plot(x, miss5)\n",
    "ax[2].set_title(\"Predictions plus training\")\n",
    "\n",
    "#plot dotted line at 0.7\n",
    "ax[0].axvline(0.7, linestyle='--')\n",
    "\n",
    "# Plot the red markes\n",
    "for point in [0.3, 0.7]:\n",
    "    value3 = 3*point**2*(1-point)\n",
    "    value5 = 5*point**4*(1-point)\n",
    "    ax[0].plot(0.7, value3, 'ro')\n",
    "    ax[0].plot(0.7, value5, 'bo')\n",
    "    ax[0].annotate(str(value3),xy=(0.7,value3))\n",
    "    ax[0].annotate(str(value5),xy=(0.7,value5))\n",
    "    \n",
    "ax[0].grid(True)\n",
    "ax[1].grid(True)\n",
    "ax[2].grid(True)\n",
    "ax[0].legend(['3 Networks Positive Training', '5 Networks Positive Training', '3 Networks Negative Training', '5 Networks Negative Training', 'x = 70%'])\n",
    "ax[1].legend(['No Prediction', 'All right', 'All wrong', 'Positive Training', 'Negative Training', 'Sum'])\n",
    "ax[2].legend(['Correct Prediction', 'Wrong Prediction', 'No Prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfTJpLJszgU4"
   },
   "source": [
    "So, this sums up the basic idea.\n",
    "\n",
    "Now a couple of questions arise: \n",
    "- Should we only posttrain later layers?\n",
    "\n",
    "  - Sounds like a good idea.\n",
    "- Should we split the dataset and adjust epochs etc. for every model?\n",
    "  - Probably.\n",
    "- How accurate should the pretrained models be?\n",
    "  - Christoph knows how to test this\n",
    "- How should we handle the case were the ensemble is unsure?\n",
    "  - Collect the data too to get it handlabeled and then train all models with it later.\n",
    "- How can we simulate changing \"real world data\"?\n",
    "  - (Doesnt work. Subclasses not correlated enough) Take cifar100. Take out a subclass for every class. Train models on classes, not subclasses. Build ensemble. Slowly add pictures of missing subclasses.\n",
    "- And still, which architectures do we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mWoMYor6HqD4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrpjZs_RwRQk"
   },
   "source": [
    "0kay broski\n",
    "\n",
    "was denn deine forschungsfrage?\n",
    "\n",
    "Wie akkurat müssen klassifizierer sein um sich gegenseitig effektiv trainieren zu können?\n",
    "\n",
    "- wohin willst du hiermit?\n",
    "  - Ich möchte herausfinden wie Continuous Training in ensemble networks funktioniert und es mit anderen techniken vergleichen\n",
    "\n",
    "- was sind die wichtigen grundlagen die erklärt werden müssen?\n",
    " - Ensemble Networks, Feed Forward Networks, CNNs, Continuous Training\n",
    "\n",
    "- \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNNtjlEikE9m+npsusDBi5H",
   "collapsed_sections": [],
   "name": "Continuous Training in Ensemble Neural Networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
